<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>LVE Repository</title>
        <link rel="stylesheet" href="/style.css">
        <meta name="description" content="LVE: We document and track vulnerabilities and exposures of large language models (LVEs).">
        <script src="/copy.js"></script>
        <script src="/instances.js"></script>
        <script src="/promptdown.dist.js"></script>
        <script src="/nav.js"></script>
        <link rel="stylesheet" href="/promptdown.css">
    
</head>
<body>
    <div class="toolbar">
    <div class="content">
        <a href="/index.html">
            <img class="logo" src="/lve.svg"/>
            <h1>LVE Repository</h1>
        </a>
        <div style="flex: 1"></div>
        <ul>
            <li> 
                <a href="/competitions">Competitions</a> 
            </li>
            <li>
                <a href="/docs">Docs</a>
            </li>
            <li class="small">
                <a href="https://discord.gg/Qgy3rqRx">
                    <img src="/discord.svg"/>
                </a>
            </li>
            <li class="small">
                <a href="https://github.com/lve-org/lve">
                    <img src="/github.png"/>
                </a>
            </li>
        </ul>
    </div>
</div>
    <div class="content docs with-sidebar">
        <div class='nav-dim' onclick='toggleNav()'></div><div class='mobile-nav'><a onclick='toggleNav()'>‚ò∞ Menu</a></div><nav class='left'><ul>
            <li class="">
                <a href="/docs/index.html"> What is the LVE Project?</a>
            </li>
            <li class='header'>Contributing</li>
            <li class="">
                <a href="/docs/contributing/guidelines.html"> Guidelines</a>
            </li>
            
            <li class="active">
                <a href="/docs/contributing/resources.html">Resources</a>
            </li>
            <li class='header'>Technical</li>
            <li class="">
                <a href="/docs/technical/checker.html">Checker</a>
            </li>
            
            <li class="">
                <a href="/docs/technical/prompt.html">Prompt</a>
            </li>
            
            <li class="">
                <a href="/docs/technical/core_checkers.html">Core Checkers</a>
            </li>
            </ul></nav>
        <div class="markdown">
         <h1 id="resources-for-finding-lves">Resources for finding LVEs</h1>
<div class="subtitle">Some resources to help you get started with LVEs.</div>

<p>The list is by no means exhaustive, so please feel free to contribute any useful resources you find to this list.</p>
<h3 id="research-papers">Research papers</h3>
<table>
<thead>
<tr>
<th>Title</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Red Teaming Language Models with Language Models</td>
<td><a href="https://arxiv.org/abs/2202.03286">https://arxiv.org/abs/2202.03286</a></td>
</tr>
<tr>
<td>Universal and Transferable Adversarial Attacks on Aligned Language Models</td>
<td><a href="https://arxiv.org/abs/2307.15043">https://arxiv.org/abs/2307.15043</a></td>
</tr>
<tr>
<td>Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models</td>
<td><a href="https://arxiv.org/abs/2309.01219">https://arxiv.org/abs/2309.01219</a></td>
</tr>
<tr>
<td>Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc</td>
<td><a href="https://arxiv.org/abs/2308.04445">https://arxiv.org/abs/2308.04445</a></td>
</tr>
<tr>
<td>Evaluating Superhuman Models with Consistency Checks</td>
<td><a href="https://arxiv.org/abs/2306.09983">https://arxiv.org/abs/2306.09983</a></td>
</tr>
<tr>
<td>Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks</td>
<td><a href="https://arxiv.org/abs/2307.02477">https://arxiv.org/abs/2307.02477</a></td>
</tr>
<tr>
<td>Not what you‚Äôve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection</td>
<td><a href="https://i.blackhat.com/BH-US-23/Presentations/US-23-Greshake-Not-what-youve-signed-up-for-whitepaper.pdf">https://i.blackhat.com/BH-US-23/Presentations/US-23-Greshake-Not-what-youve-signed-up-for-whitepaper.pdf</a></td>
</tr>
<tr>
<td>The Reversal Curse: LLMs trained on ‚ÄúA is B‚Äù fail to learn ‚ÄúB is A‚Äù</td>
<td><a href="https://owainevans.github.io/reversal_curse.pdf">https://owainevans.github.io/reversal_curse.pdf</a></td>
</tr>
<tr>
<td>In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT</td>
<td><a href="https://arxiv.org/abs/2304.08979">https://arxiv.org/abs/2304.08979</a></td>
</tr>
</tbody>
</table>
<h3 id="talks">Talks</h3>
<table>
<thead>
<tr>
<th>Title</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Compromising LLMs: The Advent of AI Malware</td>
<td><a href="https://www.blackhat.com/us-23/briefings/schedule/index.html#compromising-llms-the-advent-of-ai-malware-33075">https://www.blackhat.com/us-23/briefings/schedule/index.html#compromising-llms-the-advent-of-ai-malware-33075</a></td>
</tr>
</tbody>
</table>
<h3 id="blog-posts">Blog posts</h3>
<table>
<thead>
<tr>
<th>Title</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Evaluating Language Model Bias with ü§ó Evaluate</td>
<td><a href="https://huggingface.co/blog/evaluating-llm-bias">https://huggingface.co/blog/evaluating-llm-bias</a></td>
</tr>
<tr>
<td>What‚Äôs Wrong with Large Language Models and What We Should be Building Instead</td>
<td><a href="https://web.engr.oregonstate.edu/~tgd/talks/dietterich-fixing-llms-valgrai-2023.pdf">https://web.engr.oregonstate.edu/~tgd/talks/dietterich-fixing-llms-valgrai-2023.pdf</a></td>
</tr>
</tbody>
</table>
<h3 id="existing-datasets">Existing Datasets</h3>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Antrophic HH-RLHF</td>
<td><a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">https://huggingface.co/datasets/Anthropic/hh-rlhf</a></td>
</tr>
<tr>
<td>BOLD</td>
<td><a href="https://huggingface.co/datasets/AlexaAI/bold">https://huggingface.co/datasets/AlexaAI/bold</a></td>
</tr>
<tr>
<td>LLMonitor</td>
<td><a href="https://benchmarks.llmonitor.com/">https://benchmarks.llmonitor.com/</a></td>
</tr>
</tbody>
</table>
<h3 id="social-media">Social media</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>r/ChatGPT</td>
<td><a href="https://www.reddit.com/r/ChatGPT/">https://www.reddit.com/r/ChatGPT/</a></td>
</tr>
<tr>
<td>r/ChatGPTPromptGenius</td>
<td><a href="https://www.reddit.com/r/ChatGPTPromptGenius/">https://www.reddit.com/r/ChatGPTPromptGenius/</a></td>
</tr>
</tbody>
</table>
<h3 id="websites">Websites</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLM Security</td>
<td><a href="https://llmsecurity.net/">https://llmsecurity.net/</a></td>
</tr>
</tbody>
</table>
<h3 id="multi-modal">Multi-Modal</h3>
<p>Currently LVEs for multi-modal models are not supported.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Abusing Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs</td>
<td><a href="https://arxiv.org/abs/2307.10490">https://arxiv.org/abs/2307.10490</a></td>
</tr>
<tr>
<td>Optical Illusions</td>
<td>https://x.com/fabianstelzer/status/1717131235644875024?s=46&amp;t=OVkczsEQn03hzrb1v431AA</td>
</tr>
</tbody>
</table>
        </div>
    </div>
    </div>
</body>
</html>